% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/setup.R
\name{cross_validate_average}
\alias{cross_validate_average}
\title{This method is useful for other cross-validation methods to compute predictivity/performance. On its own it's pretty pointless.}
\usage{
cross_validate_average(
  total_data,
  ngroup = 5,
  parameter_colnames,
  summary_statistics_colnames,
  cv_seed = 0
)
}
\arguments{
\item{total_data}{A data.frame where each row represents a separate simulation run. The data.frame ought to
contain both the summary statistics (output of the model) and the parameters that generated them.}

\item{ngroup}{Number of groups to split the total data in when cross-validating. Defaults to 5}

\item{parameter_colnames}{The name of the columns in the training_runs data.frame that represent the parameters (inputs) of the
simulation model}

\item{summary_statistics_colnames}{The name of the columns in the training_runs data.frame that represent the summary statistics
(outputs) of the simulation model}

\item{cv_seed}{random seed controlling how CV groups are formed: keep it constant to compare cross-validations across methods}
}
\value{
A list containing the basic estimation results
#' \itemize{
  \item rmse - Average out of sample RMSE for all the groups in the CV  (named vector of length equal to the number of parameters)
  \item contained - The out-of-sample percentage of times the real parameters are contained in the estimated interval;
  \item interval_size - The average range between lower and upper bound of the prediction intervals for each parameter, i.e. how wide our confidence bounds are on average (named vector of length equal to the number of parameters)
  \item results list of \code{fit_gam} results, one for each CV group
  \item out_of_sample_errors a tidy data-frame containing for each row an out-of-sample prediction and error made for one parameter; useful for debugging
}
}
\description{
Performs a full-cross validation where it splits all the runs in \code{total_data}
into a set of groups, uses all but one group as \code{training_runs} in
\code{fit_average} and the last group as \code{target_runs}. Then repeats for all groups.
}
\details{
It doesn't collect any performance indicator since by construction here they all end up being 0.
}
\examples{
##generate some fake data where paramone,paramtwo ---> ssone,sswto;
## notice that paramtwo is basically unidentifiable!
paramone<-rnorm(n=5000)
paramtwo<-runif(n=5000,min=2,max=5)
ssone<-2*paramone + rnorm(n=5000)
sstwo<- paramone/paramtwo  + rnorm(n=5000)
training_data<-
  data.frame(
    paramone,
    paramtwo,
    ssone,
    sstwo
  )
### or simply do a full cross-validation
cross_validate_average<-cross_validate_gam(training_data,ngroup = 5,
                              parameter_colnames = c("paramone","paramtwo"),
                              summary_statistics_colnames = c("ssone","sstwo"))

}
